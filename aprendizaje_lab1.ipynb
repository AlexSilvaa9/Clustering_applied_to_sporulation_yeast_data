{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mb_4RbW_8IXp"
      },
      "source": [
        "# Dependencies installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install pandas\n",
        "!pip install scikit-learn\n",
        "!pip install yellowbrick\n",
        "!pip install matplotlib\n",
        "!pip install seaborn\n",
        "!pip install scipy\n",
        "!pip install numpy\n",
        "!pip install Jinja2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data importation and cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEHS68lO8Q21",
        "outputId": "d4abd2b9-d3a1-4224-8929-ff84e970008d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carga el archivo tabulado como DataFrame\n",
        "df = pd.read_csv('sporulation-filtered.txt', sep='\\t',decimal=',')\n",
        "\n",
        "#quitamos mean y variacion\n",
        "df = df[0:-2]\n",
        "y = df['Genes']\n",
        "x = df.drop('Genes',axis=1)\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame\n",
        "print(x)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VblS_J2FERsd"
      },
      "source": [
        "# Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5RYu-4pERUL",
        "outputId": "0033028b-001e-4ecd-cbe9-c3ec26f77eec"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Supongamos que ya has cargado tu DataFrame y que `x` es tu matriz de expresión\n",
        "# Normalizar usando Z-score\n",
        "x_normalized = (x - x.mean(axis=1).values[:, None]) / x.std(axis=1).values[:, None]\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame normalizado\n",
        "print(x_normalized.head())\n",
        "\n",
        "# Si necesitas concatenar los nombres de los genes de nuevo, puedes hacerlo así:\n",
        "df = pd.DataFrame(x_normalized, columns=x.columns)\n",
        "df['Genes'] = y.values  # Añadir la columna de genes\n",
        "\n",
        "# Mostrar el DataFrame normalizado\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Elbow method\n",
        "\n",
        "Now we employ the Elbow Method to identify the optimal number of clusters, k, for the k-Means algorithm.\n",
        "The Elbow Method is a well-established technique used to determine the appropriate number of clusters by\n",
        "evaluating the within-cluster sum of squares (also known as inertia) for a range of cluster values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "lbpV6G67xXsO",
        "outputId": "2bf9f987-86b3-4296-af85-61971804fe62"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "model = KMeans()\n",
        "visualizer = KElbowVisualizer(model, k=(2,9)) # a range of k values from 2 to 9\n",
        "\n",
        "visualizer.fit(x)        # Fit the data to the visualizer\n",
        "visualizer.show()        # Finalize and render the figure"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data visualization\n",
        "\n",
        "## PCA\n",
        "\n",
        "PCA is applied to the gene expression dataset to reduce its dimensionality from the original high dimensional space to two dimensions. By creating an instance of the PCA class with n_components=2,\n",
        "the code in listing 2 captures the most significant variance in the data while transforming it into a lowerdimensional representation. In this process, PCA identifies the directions (principal components) that maximize the variance of the data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "70HgANvE71kZ",
        "outputId": "c1657965-7a67-49bc-9526-187d2cde93d4"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "pca = PCA(n_components=2)\n",
        "x_pca = pca.fit_transform(x)\n",
        "\n",
        "\n",
        "plt.figure(2, figsize=(8, 6))\n",
        "plt.clf()\n",
        "plt.scatter(x_pca[:, 0], x_pca[:, 1], cmap=plt.cm.Set1, edgecolor=\"k\")\n",
        "# plt.scatter(x_pca[:, 0], x_pca[:, 1], c=y, cmap=plt.cm.Set1, edgecolor=\"k\")\n",
        "\n",
        "plt.xlabel(\"First principal component\")\n",
        "plt.ylabel(\"Second principal component\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The visualization above illustrates the clusters formed by K-means, with different colors representing\n",
        "different clusters. Additionally, the red circles indicate the centers of the clusters, providing insight into the\n",
        "central tendencies of the identified groups. This approach allows for a clearer understanding of how gene\n",
        "expression profiles are organized and related during the sporulation process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "id": "pIU1HI1KrOlk",
        "outputId": "42aae2d9-e916-4f77-9798-f2eccf168046"
      },
      "outputs": [],
      "source": [
        "clusterer = KMeans(n_clusters=4)\n",
        "cluster_labels = clusterer.fit_predict(x_pca)\n",
        "# show the actual clusters formed and centroids\n",
        "plt.figure(2, figsize=(8, 6))\n",
        "plt.clf()\n",
        "plt.scatter(x_pca[:, 0], x_pca[:, 1], c=clusterer.labels_, edgecolor=\"k\")\n",
        "# Labeling the clusters\n",
        "centers = clusterer.cluster_centers_\n",
        "# Draw red circles at cluster centers\n",
        "plt.scatter(centers[:, 0], centers[:, 1], marker=\"o\", c=\"red\", s=200, edgecolor=\"k\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MDS\n",
        "\n",
        "MDS is also used for dimensionality reduction and, like PCA, aims to preserve the\n",
        "structure of the data in a lower-dimensional space. MDS starts with a dissimilarity matrix between the\n",
        "data points and seeks a two-dimensional representation that minimizes the differences between the original\n",
        "distances and the distances in the reduced space. This focus on dissimilarities makes MDS particularly\n",
        "advantageous for clustering applications, as it can identify patterns and groupings based on the relationships\n",
        "between data points rather than solely relying on variance, as is the case with PCA."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.manifold import MDS\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Crear el modelo MDS\n",
        "mds = MDS(n_components=2, random_state=42)\n",
        "x_mds = mds.fit_transform(x)\n",
        "\n",
        "# Graficar el resultado\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.clf()\n",
        "plt.scatter(x_mds[:, 0], x_mds[:, 1], cmap=plt.cm.Set1, edgecolor=\"k\")\n",
        "# plt.scatter(x_mds[:, 0], x_mds[:, 1], c=y, cmap=plt.cm.Set1, edgecolor=\"k\")\n",
        "\n",
        "plt.xlabel(\"MDS Dimension 1\")\n",
        "plt.ylabel(\"MDS Dimension 2\")\n",
        "plt.title(\"MDS Projection\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.manifold import MDS\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Aplicar MDS para reducir la dimensionalidad\n",
        "mds = MDS(n_components=2, random_state=42)\n",
        "x_mds = mds.fit_transform(x)\n",
        "\n",
        "# Realizar el clustering con K-means\n",
        "clusterer = KMeans(n_clusters=4, random_state=42)\n",
        "cluster_labels = clusterer.fit_predict(x_mds)\n",
        "\n",
        "# Visualizar los clusters formados\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.clf()\n",
        "plt.scatter(x_mds[:, 0], x_mds[:, 1], c=cluster_labels, edgecolor=\"k\", cmap=plt.cm.Set1)\n",
        "\n",
        "# Obtener los centros de los clusters\n",
        "centers = clusterer.cluster_centers_\n",
        "\n",
        "# Dibujar círculos rojos en los centros de los clusters\n",
        "plt.scatter(centers[:, 0], centers[:, 1], marker=\"o\", c=\"red\", s=200, edgecolor=\"k\")\n",
        "\n",
        "plt.xlabel(\"MDS Dimension 1\")\n",
        "plt.ylabel(\"MDS Dimension 2\")\n",
        "plt.title(\"K-means Clustering on MDS Projection\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To see how every gene is classified in one cluster:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ERkIWS2Ajur",
        "outputId": "f1cb0cba-5697-4a30-c1d2-fc986703a51b"
      },
      "outputs": [],
      "source": [
        "cluster_labels = clusterer.fit_predict(x)\n",
        "df['cluster'] = cluster_labels\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Violin plots\n",
        "\n",
        "Violin plots effectively illustrate the distribution of each variable, enabling us to observe variations in\n",
        "central tendency and spread across clusters. This visualization is particularly valuable for interpreting how\n",
        "the characteristics of gene expression profiles differ in relation to the identified clusters over time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-WbmkZxAmuLx",
        "outputId": "f2c1f049-66da-4e01-9abb-c1f37c74865e"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "# Número de variables a graficar\n",
        "num_vars = len(df.columns[1:-1])\n",
        "\n",
        "# Calcular filas y columnas para los subplots\n",
        "cols = 3  # Número de gráficos por fila\n",
        "rows = math.ceil(num_vars / cols)  # Número de filas necesarias\n",
        "\n",
        "# Crear subplots\n",
        "fig, axes = plt.subplots(rows, cols, figsize=(cols * 6, rows * 4))\n",
        "fig.tight_layout(pad=5.0)  # Espaciado entre gráficos\n",
        "\n",
        "# Iterar sobre las variables y graficarlas\n",
        "for i, var in enumerate(df.columns[0:-1]):\n",
        "    row = i // cols\n",
        "    col = i % cols\n",
        "    sns.violinplot(x=df['cluster'], y=var, data=df, ax=axes[row, col])\n",
        "    axes[row, col].set_title(f'Violin Plot for {var} by Cluster')\n",
        "\n",
        "# Eliminar ejes vacíos si hay\n",
        "for i in range(num_vars, rows * cols):\n",
        "    fig.delaxes(axes.flat[i])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGg-6Qnl9RGk"
      },
      "source": [
        "# Clustering comparation\n",
        "\n",
        "In this section, we compare various clustering methods (k-means, agglomerative clustering, and Gaussian\n",
        "mixture models) along with different numbers of clusters. This comparison employs multiple validation\n",
        "techniques to provide a comprehensive understanding of how well these clustering methods perform on the\n",
        "dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IKQqjih_BapP",
        "outputId": "749d9205-c606-4a28-8f56-8fe6818f2f49"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.metrics import silhouette_score\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "# Crear un DataFrame para almacenar los resultados\n",
        "results = pd.DataFrame(columns=['Method', 'k', 'Silhouette Score', 'Mean Distance to Centroids', 'Average Distance Between Clusters', 'Non-Overlap Measure'])\n",
        "\n",
        "# Función para calcular la medida de no solapamiento\n",
        "def non_overlap_measure(labels):\n",
        "    unique_labels = np.unique(labels)\n",
        "    overlap = 0\n",
        "    for label in unique_labels:\n",
        "        cluster_points = labels == label\n",
        "        overlap += np.sum(cluster_points) ** 2\n",
        "    return overlap\n",
        "\n",
        "# Lista de métodos de clustering\n",
        "methods = {\n",
        "    'KMeans': KMeans,\n",
        "    'Agglomerative': AgglomerativeClustering,\n",
        "    'Gaussian Mixture': GaussianMixture\n",
        "}\n",
        "\n",
        "# Lista para almacenar los resultados\n",
        "results_list = []\n",
        "\n",
        "# Iterar sobre diferentes métodos y valores de k\n",
        "for method_name, method in methods.items():\n",
        "    for k in range(2, 15):  # Iniciar en 2 para que el Silhouette tenga sentido\n",
        "        if method_name == 'KMeans':\n",
        "            clusterer = method(n_clusters=k, random_state=42)\n",
        "            cluster_labels = clusterer.fit_predict(x)\n",
        "            centroids = clusterer.cluster_centers_\n",
        "        elif method_name == 'Agglomerative':\n",
        "            clusterer = method(n_clusters=k)\n",
        "            cluster_labels = clusterer.fit_predict(x)\n",
        "            centroids = None  # Agglomerative no tiene centroids\n",
        "        elif method_name == 'Gaussian Mixture':\n",
        "            clusterer = method(n_components=k, random_state=42)\n",
        "            cluster_labels = clusterer.fit_predict(x)\n",
        "            centroids = clusterer.means_\n",
        "\n",
        "        # Silhouette Score\n",
        "        silhouette_avg = silhouette_score(x, cluster_labels)\n",
        "\n",
        "        # Mean Distance to Centroids (solo para métodos con centros)\n",
        "        if centroids is not None:\n",
        "            mean_distance = np.mean(np.min(cdist(x, centroids), axis=1))\n",
        "        else:\n",
        "            mean_distance = np.nan\n",
        "\n",
        "        # Average Distance Between Clusters\n",
        "        avg_distance = 0\n",
        "        for i in range(k):\n",
        "            for j in range(i + 1, k):\n",
        "                avg_distance += np.mean(cdist(x[cluster_labels == i], x[cluster_labels == j]))\n",
        "        avg_distance /= (k * (k - 1)) / 2  # Promedio total\n",
        "\n",
        "        # Non-Overlap Measure\n",
        "        non_overlap = non_overlap_measure(cluster_labels)\n",
        "\n",
        "        # Almacenar resultados en una lista\n",
        "        results_list.append({\n",
        "            'Method': method_name,\n",
        "            'k': k,\n",
        "            'Silhouette Score': silhouette_avg,\n",
        "            'Mean Distance to Centroids': mean_distance,\n",
        "            'Average Distance Between Clusters': avg_distance,\n",
        "            'Non-Overlap Measure': non_overlap\n",
        "        })\n",
        "\n",
        "# Convertir la lista de resultados a un DataFrame\n",
        "results = pd.DataFrame(results_list)\n",
        "\n",
        "# Estilizar la tabla\n",
        "styled_results = results.style \\\n",
        "    .set_table_attributes('style=\"width:100%; border-collapse:collapse;\"') \\\n",
        "    .set_properties(**{'border': '1px solid black', 'text-align': 'center'}) \\\n",
        "    .background_gradient(cmap='viridis', subset=['Silhouette Score', 'Mean Distance to Centroids', 'Average Distance Between Clusters', 'Non-Overlap Measure']) \\\n",
        "    .highlight_max(color='lightgreen', axis=0, props='text-decoration: underline;') \\\n",
        "    .highlight_min(color='salmon', axis=0) \\\n",
        "    .set_caption(\"Resultados de Clustering con Distintos Métodos\") \\\n",
        "    .set_table_attributes('style=\"border: 2px solid black; border-collapse: collapse; font-size: 12px; margin: 20px 0;\"')\n",
        "\n",
        "# Guardar la tabla estilizada en HTML\n",
        "html_table = styled_results.to_html()\n",
        "with open('clustering_results.html', 'w') as f:\n",
        "    f.write(html_table)\n",
        "\n",
        "# Si deseas mostrar la tabla directamente en Jupyter Notebook (si corresponde)\n",
        "styled_results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YOllWp7PE25T",
        "outputId": "834ab96c-6a66-4734-f894-57a55bd351e7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Configuración de estilo para las gráficas\n",
        "sns.set(style='whitegrid')\n",
        "\n",
        "# Listar métricas a graficar\n",
        "metrics = ['Silhouette Score', 'Mean Distance to Centroids', 'Average Distance Between Clusters', 'Non-Overlap Measure']\n",
        "\n",
        "# Crear una gráfica para cada métrica\n",
        "for metric in metrics:\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Graficar cada método de clustering\n",
        "    for method in methods.keys():\n",
        "        # Filtrar los resultados por método\n",
        "        method_results = results[results['Method'] == method]\n",
        "\n",
        "        # Graficar la métrica correspondiente\n",
        "        plt.plot(method_results['k'], method_results[metric], marker='o', label=method)\n",
        "\n",
        "    # Configuraciones de la gráfica\n",
        "    plt.title(f'Comparison of Clustering Methods for {metric}', fontsize=16)\n",
        "    plt.xlabel('Number of Clusters (k)', fontsize=14)\n",
        "    plt.ylabel(metric, fontsize=14)\n",
        "    plt.xticks(range(2, 15))\n",
        "    plt.legend(title='Clustering Methods')\n",
        "    plt.grid(True)\n",
        "\n",
        "    # Guardar la gráfica\n",
        "    plt.savefig(f'clustering_{metric}.png')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Silhouettes analysis\n",
        "\n",
        "Since the results obtained using the previous methods do not fully align with the findings reported in\n",
        "the literature, we will now apply the silhouette method to analyze our data. This approach will allow us\n",
        "to evaluate the consistency and quality of our clustering results in a more robust manner. By using the\n",
        "silhouette method, we aim to gain deeper insights into how well-separated our clusters are, as this metric\n",
        "considers both the cohesion within clusters and the separation between different clusters. This analysis\n",
        "should help us better understand the discrepancies between our findings and those reported in the original\n",
        "article, providing a more thorough validation of our results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score\n",
        "\n",
        "# Crear un rango de valores de k\n",
        "range_k = range(2, 11)\n",
        "\n",
        "\n",
        "for k in range_k:\n",
        "    # Crear el modelo KMeans con el número de clusters k\n",
        "    kmeans = KMeans(n_clusters=k, random_state=10)\n",
        "    cluster_labels = kmeans.fit_predict(x)\n",
        "\n",
        "    # Si k es 1, el silhouette score no se puede calcular\n",
        "    if k == 1:\n",
        "        print(f\"K = {k}: El silhouette score no es aplicable.\")\n",
        "        continue\n",
        "\n",
        "    # Calcular el promedio del silhouette score para todos los puntos\n",
        "    silhouette_avg = silhouette_score(x, cluster_labels)\n",
        "    print(f\"K = {k}: Silhouette score promedio = {silhouette_avg:.3f}\")\n",
        "\n",
        "    # Calcular los valores de silueta para cada punto\n",
        "    sample_silhouette_values = silhouette_samples(x, cluster_labels)\n",
        "\n",
        "    # Crear el gráfico de siluetas\n",
        "    fig, ax1 = plt.subplots(1, 1)\n",
        "    fig.set_size_inches(7, 5)\n",
        "\n",
        "    y_lower = 10\n",
        "    for i in range(k):\n",
        "        # Agregar los valores de silueta para los clusters en orden\n",
        "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
        "        ith_cluster_silhouette_values.sort()\n",
        "\n",
        "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "        y_upper = y_lower + size_cluster_i\n",
        "\n",
        "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
        "                          0, ith_cluster_silhouette_values)\n",
        "\n",
        "        y_lower = y_upper + 10  # Espacio entre clusters\n",
        "\n",
        "    # Dibujar la línea del umbral del silhouette score promedio\n",
        "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
        "\n",
        "    ax1.set_title(f\"Gráfica de siluetas para k = {k}\")\n",
        "    ax1.set_xlabel(\"Coeficiente de silueta\")\n",
        "    ax1.set_ylabel(\"Etiqueta del cluster\")\n",
        "\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
